{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "def parse_single_file(filepath):\n",
    "    \"\"\"\n",
    "    Parse a single log file and return a DataFrame with:\n",
    "    user, selected_user, datetime, duration, document_distance, rating, query, answer, source\n",
    "\n",
    "    :param filepath: Path to a single log file.\n",
    "    :return: A pandas DataFrame with parsed log information from that file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Regex patterns\n",
    "    datetime_pattern = re.compile(r'^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}')\n",
    "    selected_user_pattern = re.compile(r'^Selected User:\\s*(.*)')\n",
    "    user_pattern = re.compile(r'^User:\\s*([0-9a-fA-F-]+)')\n",
    "    duration_pattern = re.compile(r'^Duration:\\s*([\\d.]+)\\s*seconds')\n",
    "    doc_distance_pattern = re.compile(r'^Document distance:\\s*([\\d.]+)')\n",
    "    query_pattern = re.compile(r'^Query:\\s*(.*)')\n",
    "    response_pattern = re.compile(r'^Response:\\s*(.*)')\n",
    "    rating_pattern = re.compile(r'^User\\s+([0-9a-fA-F-]+)\\s+rated the response:\\s+(\\d+)/10')\n",
    "    source_pattern = re.compile(r'^Source:\\s*(.*)')\n",
    "    \n",
    "    entries = []\n",
    "    current_entry = {}\n",
    "    collecting_response = False\n",
    "    \n",
    "    def store_and_reset(entry_dict):\n",
    "        \"\"\"Store the current entry_dict in entries if itâ€™s valid, then reset it.\"\"\"\n",
    "        if \"datetime\" in entry_dict and \"user\" in entry_dict:\n",
    "            entry_dict.setdefault(\"selected_user\", None)\n",
    "            entry_dict.setdefault(\"duration\", None)\n",
    "            entry_dict.setdefault(\"document_distance\", None)\n",
    "            entry_dict.setdefault(\"rating\", None)\n",
    "            entry_dict.setdefault(\"query\", None)\n",
    "            entry_dict.setdefault(\"answer\", None)\n",
    "            entry_dict.setdefault(\"source\", None)\n",
    "            entries.append(entry_dict)\n",
    "        return {}\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\n')\n",
    "            \n",
    "            # Check for rating line\n",
    "            rate_match = rating_pattern.match(line)\n",
    "            if rate_match:\n",
    "                rated_user = rate_match.group(1)\n",
    "                rated_value = rate_match.group(2)\n",
    "                # First, try to assign rating to the current entry if it matches the user and has no rating yet.\n",
    "                if current_entry.get(\"user\") == rated_user and (current_entry.get(\"rating\") is None or current_entry.get(\"rating\") == \"\"):\n",
    "                    current_entry[\"rating\"] = rated_value\n",
    "                else:\n",
    "                    # Otherwise, search through previously stored entries (in reverse order)\n",
    "                    for e in reversed(entries):\n",
    "                        if e.get(\"user\") == rated_user and (e.get(\"rating\") is None or e.get(\"rating\") == \"\"):\n",
    "                            e[\"rating\"] = rated_value\n",
    "                            break\n",
    "                continue\n",
    "            \n",
    "            # Check if the line starts a new block (datetime)\n",
    "            if datetime_pattern.match(line):\n",
    "                # If we're currently holding a block, store it first\n",
    "                if current_entry:\n",
    "                    current_entry = store_and_reset(current_entry)\n",
    "                \n",
    "                # Start a new block\n",
    "                current_entry[\"datetime\"] = line.strip()\n",
    "                collecting_response = False\n",
    "                continue\n",
    "            \n",
    "            # Selected user\n",
    "            select_user_match = selected_user_pattern.match(line)\n",
    "            if select_user_match:\n",
    "                current_entry[\"selected_user\"] = select_user_match.group(1).strip()\n",
    "                continue\n",
    "            \n",
    "            # User\n",
    "            user_match = user_pattern.match(line)\n",
    "            if user_match:\n",
    "                current_entry[\"user\"] = user_match.group(1).strip()\n",
    "                continue\n",
    "            \n",
    "            # Duration\n",
    "            duration_match = duration_pattern.match(line)\n",
    "            if duration_match:\n",
    "                current_entry[\"duration\"] = duration_match.group(1).strip()\n",
    "                continue\n",
    "            \n",
    "            # Document distance\n",
    "            doc_dist_match = doc_distance_pattern.match(line)\n",
    "            if doc_dist_match:\n",
    "                current_entry[\"document_distance\"] = doc_dist_match.group(1).strip()\n",
    "                continue\n",
    "            \n",
    "            # Query\n",
    "            query_match = query_pattern.match(line)\n",
    "            if query_match:\n",
    "                current_entry[\"query\"] = query_match.group(1).strip()\n",
    "                collecting_response = True\n",
    "                current_entry.setdefault(\"answer\", \"\")\n",
    "                continue\n",
    "            \n",
    "            # Collecting response\n",
    "            if collecting_response:\n",
    "                resp_match = response_pattern.match(line)\n",
    "                if resp_match:\n",
    "                    current_entry[\"answer\"] = resp_match.group(1).strip()\n",
    "                    continue\n",
    "                \n",
    "                source_match = source_pattern.match(line)\n",
    "                if source_match:\n",
    "                    current_entry[\"source\"] = source_match.group(1).strip()\n",
    "                    collecting_response = False\n",
    "                    continue\n",
    "                \n",
    "                # Separator or next block indicator\n",
    "                if line.startswith(\"---\"):\n",
    "                    collecting_response = False\n",
    "                    continue\n",
    "                \n",
    "                # Otherwise, if the line is not recognized as a new metadata field, append to the answer.\n",
    "                if not (datetime_pattern.match(line) or\n",
    "                        selected_user_pattern.match(line) or\n",
    "                        user_pattern.match(line) or\n",
    "                        duration_pattern.match(line) or\n",
    "                        doc_distance_pattern.match(line) or\n",
    "                        query_pattern.match(line) or\n",
    "                        rating_pattern.match(line) or\n",
    "                        source_pattern.match(line) or\n",
    "                        line.strip(\"-\") == \"\"):\n",
    "                    current_entry[\"answer\"] += \"\\n\" + line.strip()\n",
    "    \n",
    "    # Store the last block if any\n",
    "    if current_entry:\n",
    "        store_and_reset(current_entry)\n",
    "    \n",
    "    df = pd.DataFrame(entries, columns=[\n",
    "        \"user\",\n",
    "        \"selected_user\",\n",
    "        \"datetime\",\n",
    "        \"duration\",\n",
    "        \"document_distance\",\n",
    "        \"rating\",\n",
    "        \"query\",\n",
    "        \"answer\",\n",
    "        \"source\"\n",
    "    ])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def parse_multiple_files_to_dataframe(filepaths: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse multiple log files (specified in filepaths) and return\n",
    "    a single combined DataFrame.\n",
    "    \n",
    "    :param filepaths: A list of file paths to log files.\n",
    "    :return: A pandas DataFrame with all parsed log information combined.\n",
    "    \"\"\"\n",
    "    all_dataframes = []\n",
    "    for filepath in filepaths:\n",
    "        df_single = parse_single_file(filepath)\n",
    "        all_dataframes.append(df_single)\n",
    "    \n",
    "    if all_dataframes:\n",
    "        combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    else:\n",
    "        # If no files provided or no data\n",
    "        combined_df = pd.DataFrame(columns=[\n",
    "            \"user\",\n",
    "            \"selected_user\",\n",
    "            \"datetime\",\n",
    "            \"duration\",\n",
    "            \"document_distance\",\n",
    "            \"rating\",\n",
    "            \"query\",\n",
    "            \"answer\",\n",
    "            \"source\"\n",
    "        ])\n",
    "    \n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = parse_multiple_files_to_dataframe([\"1_chat_log.txt\", \"2_chat_log.txt\", \"3_chat_log.txt\", \"4_chat_log.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_csv(df: pd.DataFrame, filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Export the DataFrame to a CSV file without an index column.\n",
    "    The CSV will include all columns in the DataFrame (e.g., user, query, correctness).\n",
    "    \n",
    "    :param df: The DataFrame to export.\n",
    "    :param filename: The output CSV file path (e.g., 'output.csv').\n",
    "    \"\"\"\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "def read_data_from_csv(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a CSV file into a DataFrame.\n",
    "    This will include any custom columns such as 'correctness'.\n",
    "    \n",
    "    :param filename: The CSV file path to read (e.g., 'output.csv').\n",
    "    :return: A DataFrame containing the CSV data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_csv(df_log, \"my_log_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load evaluated csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data_from_csv(\"edited_my_log_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_notes(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If notes_filter is provided, return only rows where the 'notes'\n",
    "    column contains the given substring (case insensitive).\n",
    "    If invert_notes is True, return rows that do NOT contain the given substring.\n",
    "    Otherwise, return the entire DataFrame.\n",
    "    \"\"\"\n",
    "    if notes_filter is not None:\n",
    "        mask = df[\"notes\"].str.contains(notes_filter, case=False, na=False)\n",
    "        if invert_notes:\n",
    "            mask = ~mask\n",
    "        return df[mask]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223, 13)\n"
     ]
    }
   ],
   "source": [
    "def filter_users_by_question_count(df: pd.DataFrame, min_questions: int = 2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters the DataFrame to only include entries from users who have asked more than min_questions.\n",
    "\n",
    "    :param df: The input DataFrame, which must contain a 'user' column.\n",
    "    :param min_questions: The minimum number of questions a user must have asked (default is 2).\n",
    "    :return: A filtered DataFrame containing only rows for users with more than min_questions questions.\n",
    "    \"\"\"\n",
    "    # Count questions per user\n",
    "    question_counts = df[\"user\"].value_counts()\n",
    "    # Get list of users with more than min_questions\n",
    "    valid_users = question_counts[question_counts > min_questions].index\n",
    "    # Filter the DataFrame to only include these users\n",
    "    filtered_df = df[df[\"user\"].isin(valid_users)]\n",
    "    return filtered_df\n",
    "df_qa = filter_users_by_question_count(df, min_questions=2)\n",
    "print(df.shape)\n",
    "# print(filtered_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User eval\n",
    "- How many unique Users\n",
    "- User group distribution\n",
    "- How many questions per user\n",
    "- average rating per user and how many they rated\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER Metrics\n",
    "def count_unique_users(df: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    Returns the number of unique users in the DataFrame.\n",
    "    \"\"\"\n",
    "    return df[\"user\"].nunique()\n",
    "\n",
    "def questions_per_usergroup(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns the distribution of user groups based on the 'selected_user' column.\n",
    "    \"\"\"\n",
    "    return df[\"selected_user\"].value_counts()\n",
    "def user_metrics(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with the average rating, count of rating, and count of questions per user.\n",
    "    \"\"\"\n",
    "    user_metrics_df = df.groupby(\"user\").agg(\n",
    "        avg_rating=(\"rating\", \"mean\"),\n",
    "        count_rating=(\"rating\", \"count\"),\n",
    "        count_questions=(\"query\", \"count\")\n",
    "    ).reset_index()\n",
    "    return user_metrics_df\n",
    "\n",
    "def unique_users_per_usergroup(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns the number of unique users per user group.\n",
    "    \"\"\"\n",
    "    return df.groupby(\"selected_user\")[\"user\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: 26\n",
      "Questions per User group:\n",
      " selected_user\n",
      "HdM_Student    106\n",
      "random_User     65\n",
      "AI_Expert       33\n",
      "Name: count, dtype: int64\n",
      "Unique Users per Usergroup:  selected_user\n",
      "AI_Expert       1\n",
      "HdM_Student    13\n",
      "random_User    12\n",
      "Name: user, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Average rating per user:\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>count_rating</th>\n",
       "      <th>count_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02b54e4d-19c4-4495-a825-f4348a200909</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0c1917aa-11c9-4109-a4a4-9e3a3ee8e091</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0e28eca6-194c-4469-825e-9fb20786d541</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131722ec-5d5d-49f1-a8f1-16fadd44ef26</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16d43fbe-a493-4334-ac2a-443b86a56699</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45b6711b-d343-41cc-852d-7b1561f77adf</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47161965-c83d-4922-b8ef-271d3b54a3ad</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>532aad09-0dcd-415a-9512-d438b2e5f6a6</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>559ab481-fcb7-4f10-bd1c-3402f1028d8e</td>\n",
       "      <td>4.342105</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>585ffd61-0510-4ab6-be1c-458f5e9c8110</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5b8d33f8-90c6-40ed-9e4d-8f450a30bd8e</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5d1ae8c6-f12e-4085-8711-a5feecb85ef8</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>79e6ccf9-027a-4151-9ad2-0ab7b9b7d726</td>\n",
       "      <td>8.111111</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>81a47d55-d91f-4df3-abf5-6967ac273025</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9ae692de-ac28-4abf-915c-56bc7a4158c2</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>af61710c-283a-47af-be3f-df6efb82a69c</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>b2c37ca8-f014-47bd-aef2-8400aa5d6364</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b5016382-66f8-46a7-ad57-79ec8e1b5e6a</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>b5627604-78b7-41e4-97b6-1a2c79bf692a</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ba4e59ab-4381-49f1-919b-974a573d82a3</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>c3ed31f5-13f8-41e1-9f94-44ce44c5b198</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>c8eab672-097f-4a43-99d4-95d4ea9c24d7</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>eec87963-3f2a-4872-adc4-931d3e23eb2a</td>\n",
       "      <td>2.612903</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>f2f472ab-a3c7-4b79-b40e-61e44645a4a3</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>f3052261-b857-4299-9535-1fcde4a5e5d1</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>f3a9be4d-a7a3-4878-a9d0-5a656acf589c</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user  avg_rating  count_rating  \\\n",
       "0   02b54e4d-19c4-4495-a825-f4348a200909    4.800000             5   \n",
       "1   0c1917aa-11c9-4109-a4a4-9e3a3ee8e091    6.500000             4   \n",
       "2   0e28eca6-194c-4469-825e-9fb20786d541    2.333333             3   \n",
       "3   131722ec-5d5d-49f1-a8f1-16fadd44ef26    3.333333             3   \n",
       "4   16d43fbe-a493-4334-ac2a-443b86a56699    7.000000             3   \n",
       "5   45b6711b-d343-41cc-852d-7b1561f77adf    6.000000             8   \n",
       "6   47161965-c83d-4922-b8ef-271d3b54a3ad    5.500000             4   \n",
       "7   532aad09-0dcd-415a-9512-d438b2e5f6a6    3.142857             7   \n",
       "8   559ab481-fcb7-4f10-bd1c-3402f1028d8e    4.342105            38   \n",
       "9   585ffd61-0510-4ab6-be1c-458f5e9c8110    5.000000             5   \n",
       "10  5b8d33f8-90c6-40ed-9e4d-8f450a30bd8e    6.333333             3   \n",
       "11  5d1ae8c6-f12e-4085-8711-a5feecb85ef8    6.142857             7   \n",
       "12  79e6ccf9-027a-4151-9ad2-0ab7b9b7d726    8.111111             9   \n",
       "13  81a47d55-d91f-4df3-abf5-6967ac273025    4.800000             5   \n",
       "14  9ae692de-ac28-4abf-915c-56bc7a4158c2    7.875000             8   \n",
       "15  af61710c-283a-47af-be3f-df6efb82a69c    6.000000             5   \n",
       "16  b2c37ca8-f014-47bd-aef2-8400aa5d6364    6.000000            12   \n",
       "17  b5016382-66f8-46a7-ad57-79ec8e1b5e6a    3.833333             6   \n",
       "18  b5627604-78b7-41e4-97b6-1a2c79bf692a    5.400000             5   \n",
       "19  ba4e59ab-4381-49f1-919b-974a573d82a3    6.571429             7   \n",
       "20  c3ed31f5-13f8-41e1-9f94-44ce44c5b198    2.333333             3   \n",
       "21  c8eab672-097f-4a43-99d4-95d4ea9c24d7    8.000000             3   \n",
       "22  eec87963-3f2a-4872-adc4-931d3e23eb2a    2.612903            31   \n",
       "23  f2f472ab-a3c7-4b79-b40e-61e44645a4a3    6.333333             6   \n",
       "24  f3052261-b857-4299-9535-1fcde4a5e5d1    2.333333             6   \n",
       "25  f3a9be4d-a7a3-4878-a9d0-5a656acf589c    4.000000             3   \n",
       "\n",
       "    count_questions  \n",
       "0                 5  \n",
       "1                 4  \n",
       "2                 3  \n",
       "3                 3  \n",
       "4                 3  \n",
       "5                 8  \n",
       "6                 5  \n",
       "7                 7  \n",
       "8                38  \n",
       "9                 7  \n",
       "10                3  \n",
       "11                7  \n",
       "12                9  \n",
       "13                5  \n",
       "14                8  \n",
       "15                5  \n",
       "16               12  \n",
       "17                6  \n",
       "18                5  \n",
       "19                7  \n",
       "20                3  \n",
       "21                3  \n",
       "22               33  \n",
       "23                6  \n",
       "24                6  \n",
       "25                3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Unique users:\", count_unique_users(df_qa))\n",
    "print(\"Questions per User group:\\n\", questions_per_usergroup(df_qa))\n",
    "print(\"Unique Users per Usergroup: \", unique_users_per_usergroup(df_qa))\n",
    "display(\"Average rating per user:\\n\", user_metrics(df_qa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users: 39\n",
      "Questions per User group:\n",
      " selected_user\n",
      "HdM_Student    115\n",
      "random_User     74\n",
      "AI_Expert       34\n",
      "Name: count, dtype: int64\n",
      "Unique Users per Usergroup:  selected_user\n",
      "AI_Expert       2\n",
      "HdM_Student    19\n",
      "random_User    18\n",
      "Name: user, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Average rating per user:\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>count_rating</th>\n",
       "      <th>count_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02b54e4d-19c4-4495-a825-f4348a200909</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0c1917aa-11c9-4109-a4a4-9e3a3ee8e091</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0e28eca6-194c-4469-825e-9fb20786d541</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11ab7e31-e352-47cd-8a00-fcb7e8bc9e71</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131722ec-5d5d-49f1-a8f1-16fadd44ef26</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16d43fbe-a493-4334-ac2a-443b86a56699</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>282a5c24-767b-47e3-8f4b-3d20bcc869fb</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>290e4b39-110d-4f87-b82e-2be7d832868f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3bbcb4ef-c51a-4857-8f9e-5cad94f151df</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44e246be-15f0-476e-892a-91288511ba38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>45b6711b-d343-41cc-852d-7b1561f77adf</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>47161965-c83d-4922-b8ef-271d3b54a3ad</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4d02548a-0643-44fa-ad1e-4a3fca680b60</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>532aad09-0dcd-415a-9512-d438b2e5f6a6</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>559ab481-fcb7-4f10-bd1c-3402f1028d8e</td>\n",
       "      <td>4.342105</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>585ffd61-0510-4ab6-be1c-458f5e9c8110</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5b8d33f8-90c6-40ed-9e4d-8f450a30bd8e</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5d1ae8c6-f12e-4085-8711-a5feecb85ef8</td>\n",
       "      <td>6.142857</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5f5d600c-1c23-48d3-80d4-aa5d1ee4469d</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>79e6ccf9-027a-4151-9ad2-0ab7b9b7d726</td>\n",
       "      <td>8.111111</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>81a47d55-d91f-4df3-abf5-6967ac273025</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9ae692de-ac28-4abf-915c-56bc7a4158c2</td>\n",
       "      <td>7.875000</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a0b06476-a7dd-4fd2-86b0-65b51e8b1c21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>a95cb11b-9ce3-4abe-b969-3f49ffa45dd7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ad1205e7-5918-4599-b8c5-bc6c91774c61</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>af61710c-283a-47af-be3f-df6efb82a69c</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>b0ab76c3-21d7-4c32-9141-3cf705e9cad5</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>b2c37ca8-f014-47bd-aef2-8400aa5d6364</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>b5016382-66f8-46a7-ad57-79ec8e1b5e6a</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b5627604-78b7-41e4-97b6-1a2c79bf692a</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ba4e59ab-4381-49f1-919b-974a573d82a3</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>c3ed31f5-13f8-41e1-9f94-44ce44c5b198</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>c8eab672-097f-4a43-99d4-95d4ea9c24d7</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>df09787e-f1bc-4025-9a4e-f041a26e096d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>eec87963-3f2a-4872-adc4-931d3e23eb2a</td>\n",
       "      <td>2.612903</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>f2f472ab-a3c7-4b79-b40e-61e44645a4a3</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>f3052261-b857-4299-9535-1fcde4a5e5d1</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>f3a9be4d-a7a3-4878-a9d0-5a656acf589c</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>fa43598c-6719-4c0a-983e-449c29db00d6</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user  avg_rating  count_rating  \\\n",
       "0   02b54e4d-19c4-4495-a825-f4348a200909    4.800000             5   \n",
       "1   0c1917aa-11c9-4109-a4a4-9e3a3ee8e091    6.500000             4   \n",
       "2   0e28eca6-194c-4469-825e-9fb20786d541    2.333333             3   \n",
       "3   11ab7e31-e352-47cd-8a00-fcb7e8bc9e71    6.000000             2   \n",
       "4   131722ec-5d5d-49f1-a8f1-16fadd44ef26    3.333333             3   \n",
       "5   16d43fbe-a493-4334-ac2a-443b86a56699    7.000000             3   \n",
       "6   282a5c24-767b-47e3-8f4b-3d20bcc869fb    9.000000             2   \n",
       "7   290e4b39-110d-4f87-b82e-2be7d832868f         NaN             0   \n",
       "8   3bbcb4ef-c51a-4857-8f9e-5cad94f151df    4.000000             2   \n",
       "9   44e246be-15f0-476e-892a-91288511ba38         NaN             0   \n",
       "10  45b6711b-d343-41cc-852d-7b1561f77adf    6.000000             8   \n",
       "11  47161965-c83d-4922-b8ef-271d3b54a3ad    5.500000             4   \n",
       "12  4d02548a-0643-44fa-ad1e-4a3fca680b60   10.000000             1   \n",
       "13  532aad09-0dcd-415a-9512-d438b2e5f6a6    3.142857             7   \n",
       "14  559ab481-fcb7-4f10-bd1c-3402f1028d8e    4.342105            38   \n",
       "15  585ffd61-0510-4ab6-be1c-458f5e9c8110    5.000000             5   \n",
       "16  5b8d33f8-90c6-40ed-9e4d-8f450a30bd8e    6.333333             3   \n",
       "17  5d1ae8c6-f12e-4085-8711-a5feecb85ef8    6.142857             7   \n",
       "18  5f5d600c-1c23-48d3-80d4-aa5d1ee4469d    2.000000             1   \n",
       "19  79e6ccf9-027a-4151-9ad2-0ab7b9b7d726    8.111111             9   \n",
       "20  81a47d55-d91f-4df3-abf5-6967ac273025    4.800000             5   \n",
       "21  9ae692de-ac28-4abf-915c-56bc7a4158c2    7.875000             8   \n",
       "22  a0b06476-a7dd-4fd2-86b0-65b51e8b1c21         NaN             0   \n",
       "23  a95cb11b-9ce3-4abe-b969-3f49ffa45dd7         NaN             0   \n",
       "24  ad1205e7-5918-4599-b8c5-bc6c91774c61   10.000000             1   \n",
       "25  af61710c-283a-47af-be3f-df6efb82a69c    6.000000             5   \n",
       "26  b0ab76c3-21d7-4c32-9141-3cf705e9cad5    5.500000             2   \n",
       "27  b2c37ca8-f014-47bd-aef2-8400aa5d6364    6.000000            12   \n",
       "28  b5016382-66f8-46a7-ad57-79ec8e1b5e6a    3.833333             6   \n",
       "29  b5627604-78b7-41e4-97b6-1a2c79bf692a    5.400000             5   \n",
       "30  ba4e59ab-4381-49f1-919b-974a573d82a3    6.571429             7   \n",
       "31  c3ed31f5-13f8-41e1-9f94-44ce44c5b198    2.333333             3   \n",
       "32  c8eab672-097f-4a43-99d4-95d4ea9c24d7    8.000000             3   \n",
       "33  df09787e-f1bc-4025-9a4e-f041a26e096d         NaN             0   \n",
       "34  eec87963-3f2a-4872-adc4-931d3e23eb2a    2.612903            31   \n",
       "35  f2f472ab-a3c7-4b79-b40e-61e44645a4a3    6.333333             6   \n",
       "36  f3052261-b857-4299-9535-1fcde4a5e5d1    2.333333             6   \n",
       "37  f3a9be4d-a7a3-4878-a9d0-5a656acf589c    4.000000             3   \n",
       "38  fa43598c-6719-4c0a-983e-449c29db00d6    3.000000             1   \n",
       "\n",
       "    count_questions  \n",
       "0                 5  \n",
       "1                 4  \n",
       "2                 3  \n",
       "3                 2  \n",
       "4                 3  \n",
       "5                 3  \n",
       "6                 2  \n",
       "7                 1  \n",
       "8                 2  \n",
       "9                 1  \n",
       "10                8  \n",
       "11                5  \n",
       "12                2  \n",
       "13                7  \n",
       "14               38  \n",
       "15                7  \n",
       "16                3  \n",
       "17                7  \n",
       "18                1  \n",
       "19                9  \n",
       "20                5  \n",
       "21                8  \n",
       "22                1  \n",
       "23                1  \n",
       "24                1  \n",
       "25                5  \n",
       "26                2  \n",
       "27               12  \n",
       "28                6  \n",
       "29                5  \n",
       "30                7  \n",
       "31                3  \n",
       "32                3  \n",
       "33                2  \n",
       "34               33  \n",
       "35                6  \n",
       "36                6  \n",
       "37                3  \n",
       "38                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Unique users:\", count_unique_users(df))\n",
    "print(\"Questions per User group:\\n\", questions_per_usergroup(df))\n",
    "print(\"Unique Users per Usergroup: \", unique_users_per_usergroup(df))\n",
    "display(\"Average rating per user:\\n\", user_metrics(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223, 13)\n",
      "(204, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df_qa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204, 13)\n",
      "(204, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df_qa.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct\n",
    "- How many are correct (total, relevant, irrelevant)?\n",
    "- How many are incorrect (total, relevant, irrelevant)?\n",
    "- Correct with good source (used, not used)\n",
    "- Correct with bad sources (used, not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECT / INCORRECT Metrics\n",
    "\n",
    "def count_correct_total(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> int:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    return df_filtered[df_filtered[\"correct\"] == True].shape[0]\n",
    "\n",
    "def count_correct_relevant(df: pd.DataFrame) -> int:\n",
    "    # Relevant: rows whose notes do NOT contain \"irrelevant\"\n",
    "    return count_correct_total(df, notes_filter=\"irrelevant\", invert_notes=True)\n",
    "\n",
    "def count_correct_irrelevant(df: pd.DataFrame) -> int:\n",
    "    # Irrelevant: rows whose notes contain \"irrelevant\"\n",
    "    return count_correct_total(df, notes_filter=\"irrelevant\", invert_notes=False)\n",
    "\n",
    "def count_incorrect_total(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> int:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    return df_filtered[df_filtered[\"correct\"] == False].shape[0]\n",
    "\n",
    "def count_incorrect_relevant(df: pd.DataFrame) -> int:\n",
    "    return count_incorrect_total(df, notes_filter=\"irrelevant\", invert_notes=True)\n",
    "\n",
    "def count_incorrect_irrelevant(df: pd.DataFrame) -> int:\n",
    "    return count_incorrect_total(df, notes_filter=\"irrelevant\", invert_notes=False)\n",
    "\n",
    "def count_incorrect_relevant_by_user_group(df: pd.DataFrame, user_group: str) -> int:\n",
    "    df_filtered = filter_by_user_group(df, user_group)\n",
    "    return count_incorrect_relevant(df_filtered)\n",
    "\n",
    "def count_incorrect_irrelevant_by_user_group(df: pd.DataFrame, user_group: str) -> int:\n",
    "    df_filtered = filter_by_user_group(df, user_group)\n",
    "    return count_incorrect_irrelevant(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct (total): 56\n",
      "Incorrect (total): 148\n",
      "Correct (relevant): 45\n",
      "Correct (irrelevant): 11\n",
      "Incorrect (total): 148\n",
      "Incorrect (relevant): 125\n",
      "Incorrect (irrelevant): 23\n",
      "\n",
      "relevant: 170, irrelevant: 34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct (total):\", count_correct_total(df))\n",
    "print(\"Incorrect (total):\", 204-count_correct_total(df))\n",
    "print(\"Correct (relevant):\", count_correct_relevant(df))\n",
    "print(\"Correct (irrelevant):\", count_correct_irrelevant(df))\n",
    "print(\"Incorrect (total):\", count_incorrect_total(df))\n",
    "print(\"Incorrect (relevant):\", count_incorrect_relevant(df))\n",
    "print(\"Incorrect (irrelevant):\", count_incorrect_irrelevant(df))\n",
    "print(\"\\nrelevant: 170, irrelevant: 34\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGE Ratings\n",
    "\n",
    "def average_rating_all(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    ratings = pd.to_numeric(df_filtered[\"rating\"], errors=\"coerce\")\n",
    "    return ratings.mean()\n",
    "\n",
    "def average_rating_correct_total(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    ratings = pd.to_numeric(df_filtered[df_filtered[\"correct\"] == True][\"rating\"], errors=\"coerce\")\n",
    "    return ratings.mean()\n",
    "\n",
    "def average_rating_correct_relevant(df: pd.DataFrame) -> float:\n",
    "    return average_rating_correct_total(df, notes_filter=\"irrelevant\", invert_notes=True)\n",
    "\n",
    "def average_rating_correct_irrelevant(df: pd.DataFrame) -> float:\n",
    "    return average_rating_correct_total(df, notes_filter=\"irrelevant\", invert_notes=False)\n",
    "\n",
    "def average_rating_incorrect_total(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    ratings = pd.to_numeric(df_filtered[df_filtered[\"correct\"] == False][\"rating\"], errors=\"coerce\")\n",
    "    return ratings.mean()\n",
    "\n",
    "def average_rating_incorrect_relevant(df: pd.DataFrame) -> float:\n",
    "    return average_rating_incorrect_total(df, notes_filter=\"irrelevant\", invert_notes=True)\n",
    "\n",
    "def average_rating_incorrect_irrelevant(df: pd.DataFrame) -> float:\n",
    "    return average_rating_incorrect_total(df, notes_filter=\"irrelevant\", invert_notes=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rating (all): 4.8542713567839195\n",
      "Average Rating (Correct Total): 8.166666666666666\n",
      "Average Rating (Correct Relevant): 8.022727272727273\n",
      "Average Rating (Correct Irrelevant): 8.8\n",
      "Average Rating (Incorrect Total): 3.6206896551724137\n",
      "Average Rating (Incorrect Relevant): 3.7154471544715446\n",
      "Average Rating (Incorrect Irrelevant): 3.090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Average Ratings\n",
    "print(\"Average Rating (all):\", average_rating_all(df))\n",
    "print(\"Average Rating (Correct Total):\", average_rating_correct_total(df))\n",
    "print(\"Average Rating (Correct Relevant):\", average_rating_correct_relevant(df))\n",
    "print(\"Average Rating (Correct Irrelevant):\", average_rating_correct_irrelevant(df))\n",
    "print(\"Average Rating (Incorrect Total):\", average_rating_incorrect_total(df))\n",
    "print(\"Average Rating (Incorrect Relevant):\", average_rating_incorrect_relevant(df))\n",
    "print(\"Average Rating (Incorrect Irrelevant):\", average_rating_incorrect_irrelevant(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "- Amount of good sources\n",
    "- Amount of bad sources\n",
    "- Amount of sources used\n",
    "- Amount of good sources that were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCES Metrics\n",
    "\n",
    "def count_correct_good_source_used(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> int:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    cond = (df_filtered[\"correct\"] == True) & \\\n",
    "           (df_filtered[\"good source\"] == True) & \\\n",
    "           (df_filtered[\"source used\"] == True)\n",
    "    return df_filtered[cond].shape[0]\n",
    "\n",
    "def count_correct_good_source_not_used(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> int:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    cond = (df_filtered[\"correct\"] == True) & \\\n",
    "           (df_filtered[\"good source\"] == True) & \\\n",
    "           (df_filtered[\"source used\"] == False)\n",
    "    return df_filtered[cond].shape[0]\n",
    "\n",
    "def count_correct_bad_source_used(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> int:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    cond = (df_filtered[\"correct\"] == True) & \\\n",
    "           (df_filtered[\"good source\"] == False) & \\\n",
    "           (df_filtered[\"source used\"] == True)\n",
    "    return df_filtered[cond].shape[0]\n",
    "\n",
    "def count_correct_bad_source_not_used(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> int:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    cond = (df_filtered[\"correct\"] == True) & \\\n",
    "           (df_filtered[\"good source\"] == False) & \\\n",
    "           (df_filtered[\"source used\"] == False)\n",
    "    return df_filtered[cond].shape[0]\n",
    "\n",
    "def count_good_sources(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> int:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    return df_filtered[df_filtered[\"good source\"] == True].shape[0]\n",
    "\n",
    "def count_bad_sources(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> int:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    return df_filtered[df_filtered[\"good source\"] == False].shape[0]\n",
    "\n",
    "def count_sources_used(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> int:\n",
    "    \"\"\"\n",
    "    Count how many rows have 'source used' == True.\n",
    "    \"\"\"\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    return df_filtered[df_filtered[\"source used\"] == True].shape[0]\n",
    "\n",
    "def count_good_sources_used(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> int:\n",
    "    \"\"\"\n",
    "    Count rows where 'good source' is True and 'source used' is True.\n",
    "    \"\"\"\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    cond = (df_filtered[\"good source\"] == True) & (df_filtered[\"source used\"] == True)\n",
    "    return df_filtered[cond].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct & Good Source Used: 27\n",
      "Correct & Good Source Not Used: 0\n",
      "Correct & Bad Source Used: 5\n",
      "Correct & Bad Source Not Used: 24\n",
      "Good Sources Count: 42\n",
      "Bad Sources Count: 162\n",
      "Sources Used Count: 75\n",
      "Sources Unused Count: 129\n",
      "Good Sources Used Count: 35\n"
     ]
    }
   ],
   "source": [
    "# Correct with Good/Bad Source â€“ Used vs. Not Used\n",
    "print(\"Correct & Good Source Used:\", count_correct_good_source_used(df))\n",
    "print(\"Correct & Good Source Not Used:\", count_correct_good_source_not_used(df))\n",
    "print(\"Correct & Bad Source Used:\", count_correct_bad_source_used(df))\n",
    "print(\"Correct & Bad Source Not Used:\", count_correct_bad_source_not_used(df))\n",
    "\n",
    "print(\"Good Sources Count:\", count_good_sources(df))\n",
    "print(\"Bad Sources Count:\", count_bad_sources(df))\n",
    "print(\"Sources Used Count:\", count_sources_used(df))\n",
    "print(\"Sources Unused Count:\", 204-count_sources_used(df))\n",
    "print(\"Good Sources Used Count:\", count_good_sources_used(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duration\n",
    "- average duration (total, correct, incorrect)\n",
    "- average duration good source\n",
    "- average duration bad source\n",
    "- average duration source used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DURATION Metrics\n",
    "\n",
    "def average_duration_total(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    durations = pd.to_numeric(df_filtered[\"duration\"], errors=\"coerce\")\n",
    "    return durations.mean()\n",
    "\n",
    "def average_duration_correct(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    durations = pd.to_numeric(df_filtered[df_filtered[\"correct\"] == True][\"duration\"], errors=\"coerce\")\n",
    "    return durations.mean()\n",
    "\n",
    "def average_duration_incorrect(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    durations = pd.to_numeric(df_filtered[df_filtered[\"correct\"] == False][\"duration\"], errors=\"coerce\")\n",
    "    return durations.mean()\n",
    "\n",
    "def average_duration_good_source(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    durations = pd.to_numeric(df_filtered[df_filtered[\"good source\"] == True][\"duration\"], errors=\"coerce\")\n",
    "    return durations.mean()\n",
    "\n",
    "def average_duration_bad_source(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    durations = pd.to_numeric(df_filtered[df_filtered[\"good source\"] == False][\"duration\"], errors=\"coerce\")\n",
    "    return durations.mean()\n",
    "\n",
    "def average_duration_source_used(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    durations = pd.to_numeric(df_filtered[df_filtered[\"source used\"] == True][\"duration\"], errors=\"coerce\")\n",
    "    return durations.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max Duration: 28.75, min Duration: 0.72\n",
      "Average Duration (Total): 12.909313725490197\n",
      "Average Duration (Correct): 13.04142857142857\n",
      "Average Duration (Incorrect): 12.859324324324323\n",
      "Average Duration (Good Source): 12.865\n",
      "Average Duration (Bad Source): 12.920802469135802\n",
      "Average Duration (Source Used): 14.08066666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"max Duration: {df[\"duration\"].max()}, min Duration: {df[\"duration\"].min()}\")\n",
    "print(\"Average Duration (Total):\", average_duration_total(df))\n",
    "print(\"Average Duration (Correct):\", average_duration_correct(df))\n",
    "print(\"Average Duration (Incorrect):\", average_duration_incorrect(df))\n",
    "print(\"Average Duration (Good Source):\", average_duration_good_source(df))\n",
    "print(\"Average Duration (Bad Source):\", average_duration_bad_source(df))\n",
    "print(\"Average Duration (Source Used):\", average_duration_source_used(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance\n",
    "- average distance (total, correct, incorrect)\n",
    "- average distance good source\n",
    "- average distance bad source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISTANCE Metrics\n",
    "\n",
    "def average_distance_total(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    distances = pd.to_numeric(df_filtered[\"document_distance\"], errors=\"coerce\")\n",
    "    return distances.mean()\n",
    "\n",
    "def average_distance_correct(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    distances = pd.to_numeric(df_filtered[df_filtered[\"correct\"] == True][\"document_distance\"], errors=\"coerce\")\n",
    "    return distances.mean()\n",
    "\n",
    "def average_distance_incorrect(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    distances = pd.to_numeric(df_filtered[df_filtered[\"correct\"] == False][\"document_distance\"], errors=\"coerce\")\n",
    "    return distances.mean()\n",
    "\n",
    "def average_distance_good_source(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    distances = pd.to_numeric(df_filtered[df_filtered[\"good source\"] == True][\"document_distance\"], errors=\"coerce\")\n",
    "    return distances.mean()\n",
    "\n",
    "def average_distance_bad_source(df: pd.DataFrame, notes_filter: str = None, invert_notes: bool = False) -> float:\n",
    "    df_filtered = filter_by_notes(df, notes_filter, invert_notes)\n",
    "    distances = pd.to_numeric(df_filtered[df_filtered[\"good source\"] == False][\"document_distance\"], errors=\"coerce\")\n",
    "    return distances.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Distance:  1.313294529914856\n",
      "Min Distance:  0.56654292345047\n",
      "Average Distance (Total): 0.9212011052112953\n",
      "Average Distance (Correct, relevant): 0.8622856987847223\n",
      "Average Distance (Correct, irrelevant): 0.9578026045452465\n",
      "Average Distance (Incorrect, relevant): 0.9035089030265808\n",
      "Average Distance (Incorrect, irrelevant): 1.115118586498758\n",
      "Average Distance (Good Source, irrelvant): 0.8208974599838257\n",
      "Average Distance (Bad Source): 0.9401338288077602\n"
     ]
    }
   ],
   "source": [
    "print(\"Max Distance: \", df[\"document_distance\"].max())\n",
    "print(\"Min Distance: \", df[\"document_distance\"].min())\n",
    "\n",
    "print(\"Average Distance (Total):\", average_distance_total(df))\n",
    "print(\"Average Distance (Correct, relevant):\", average_distance_correct(df, \"irrelevant\", True))\n",
    "print(\"Average Distance (Correct, irrelevant):\", average_distance_correct(df, \"irrelevant\"))\n",
    "print(\"Average Distance (Incorrect, relevant):\", average_distance_incorrect(df, \"irrelevant\", True))\n",
    "print(\"Average Distance (Incorrect, irrelevant):\", average_distance_incorrect(df, \"irrelevant\"))\n",
    "print(\"Average Distance (Good Source, irrelvant):\", average_distance_good_source(df, \"irrelevant\"))\n",
    "print(\"Average Distance (Bad Source):\", average_distance_bad_source(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overarch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_user_groups_extended(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with one row per user group (from 'selected_user') plus an extra row for all users.\n",
    "    For each group, it computes:\n",
    "      - correct_count: Number of responses with correct == True\n",
    "      - incorrect_count: Number of responses with correct == False\n",
    "      - average_rating_total: Average rating over all responses\n",
    "      - average_rating_correct: Average rating for responses where correct == True\n",
    "      - average_rating_incorrect: Average rating for responses where correct == False\n",
    "      - average_duration_total: Average duration over all responses\n",
    "      - average_duration_correct: Average duration for correct responses\n",
    "      - average_duration_incorrect: Average duration for incorrect responses\n",
    "      - average_distance_total: Average document distance over all responses\n",
    "      - average_distance_correct: Average distance for correct responses\n",
    "      - average_distance_incorrect: Average distance for incorrect responses\n",
    "    \"\"\"\n",
    "    # Create a copy and convert columns to numeric\n",
    "    df = df.copy()\n",
    "    df[\"rating_numeric\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n",
    "    df[\"duration_numeric\"] = pd.to_numeric(df[\"duration\"], errors=\"coerce\")\n",
    "    df[\"distance_numeric\"] = pd.to_numeric(df[\"document_distance\"], errors=\"coerce\")\n",
    "    \n",
    "    def compute_metrics(group: pd.DataFrame) -> pd.Series:\n",
    "        # Filter rows for correct and incorrect responses\n",
    "        correct = group[group[\"correct\"] == True]\n",
    "        incorrect = group[group[\"correct\"] == False]\n",
    "        \n",
    "        return pd.Series({\n",
    "            \"correct_count\": (group[\"correct\"] == True).sum(),\n",
    "            \"incorrect_count\": (group[\"correct\"] == False).sum(),\n",
    "            \"average_rating_total\": group[\"rating_numeric\"].mean(),\n",
    "            \"average_rating_correct\": correct[\"rating_numeric\"].mean() if not correct.empty else None,\n",
    "            \"average_rating_incorrect\": incorrect[\"rating_numeric\"].mean() if not incorrect.empty else None,\n",
    "            \"average_duration_total\": group[\"duration_numeric\"].mean(),\n",
    "            # \"average_duration_correct\": correct[\"duration_numeric\"].mean() if not correct.empty else None,\n",
    "            # \"average_duration_incorrect\": incorrect[\"duration_numeric\"].mean() if not incorrect.empty else None,\n",
    "            \"average_distance_total\": group[\"distance_numeric\"].mean(),\n",
    "            \"average_distance_correct\": correct[\"distance_numeric\"].mean() if not correct.empty else None,\n",
    "            \"average_distance_incorrect\": incorrect[\"distance_numeric\"].mean() if not incorrect.empty else None,\n",
    "        })\n",
    "    \n",
    "    # Group by the user group and compute metrics\n",
    "    grouped = df.groupby(\"selected_user\").apply(compute_metrics).reset_index()\n",
    "    \n",
    "    # Compute overall metrics for all users\n",
    "    overall = compute_metrics(df)\n",
    "    overall[\"selected_user\"] = \"All Users\"\n",
    "    overall_df = pd.DataFrame([overall])\n",
    "    \n",
    "    # Append the overall row\n",
    "    result = pd.concat([grouped, overall_df], ignore_index=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4619/261189169.py:43: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped = df.groupby(\"selected_user\").apply(compute_metrics).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_user</th>\n",
       "      <th>correct_count</th>\n",
       "      <th>incorrect_count</th>\n",
       "      <th>average_rating_total</th>\n",
       "      <th>average_rating_correct</th>\n",
       "      <th>average_rating_incorrect</th>\n",
       "      <th>average_duration_total</th>\n",
       "      <th>average_distance_total</th>\n",
       "      <th>average_distance_correct</th>\n",
       "      <th>average_distance_incorrect</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI_Expert</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.612903</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.769231</td>\n",
       "      <td>11.479697</td>\n",
       "      <td>0.871528</td>\n",
       "      <td>0.858722</td>\n",
       "      <td>0.874374</td>\n",
       "      <td>18.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HdM_Student</td>\n",
       "      <td>33.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>5.047170</td>\n",
       "      <td>8.060606</td>\n",
       "      <td>3.684932</td>\n",
       "      <td>12.914906</td>\n",
       "      <td>0.930921</td>\n",
       "      <td>0.890926</td>\n",
       "      <td>0.949001</td>\n",
       "      <td>31.132075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_User</td>\n",
       "      <td>17.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.645161</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>4.565217</td>\n",
       "      <td>13.626000</td>\n",
       "      <td>0.930569</td>\n",
       "      <td>0.869753</td>\n",
       "      <td>0.952108</td>\n",
       "      <td>26.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All Users</td>\n",
       "      <td>56.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>4.854271</td>\n",
       "      <td>8.166667</td>\n",
       "      <td>3.620690</td>\n",
       "      <td>12.909314</td>\n",
       "      <td>0.921201</td>\n",
       "      <td>0.881048</td>\n",
       "      <td>0.936394</td>\n",
       "      <td>27.450980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  selected_user  correct_count  incorrect_count  average_rating_total  \\\n",
       "0     AI_Expert            6.0             27.0              2.612903   \n",
       "1   HdM_Student           33.0             73.0              5.047170   \n",
       "2   random_User           17.0             48.0              5.645161   \n",
       "3     All Users           56.0            148.0              4.854271   \n",
       "\n",
       "   average_rating_correct  average_rating_incorrect  average_duration_total  \\\n",
       "0                7.000000                  1.769231               11.479697   \n",
       "1                8.060606                  3.684932               12.914906   \n",
       "2                8.750000                  4.565217               13.626000   \n",
       "3                8.166667                  3.620690               12.909314   \n",
       "\n",
       "   average_distance_total  average_distance_correct  \\\n",
       "0                0.871528                  0.858722   \n",
       "1                0.930921                  0.890926   \n",
       "2                0.930569                  0.869753   \n",
       "3                0.921201                  0.881048   \n",
       "\n",
       "   average_distance_incorrect   accuracy  \n",
       "0                    0.874374  18.181818  \n",
       "1                    0.949001  31.132075  \n",
       "2                    0.952108  26.153846  \n",
       "3                    0.936394  27.450980  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_group_evaluation = evaluate_user_groups_extended(df)\n",
    "# Calculate accuracy for each user group as a new column in the evaluation DataFrame\n",
    "user_group_evaluation['accuracy'] = (user_group_evaluation['correct_count'] / (\n",
    "    user_group_evaluation['correct_count'] + user_group_evaluation['incorrect_count']\n",
    ")) *100\n",
    "\n",
    "\n",
    "display(user_group_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_irrelevant_rows(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a new DataFrame with all rows removed where the 'notes'\n",
    "    column contains the substring 'irrelevant' (case insensitive).\n",
    "    \"\"\"\n",
    "    return df[~df[\"notes\"].str.contains(\"irrelevant\", case=False, na=False)]\n",
    "\n",
    "df_clean = remove_irrelevant_rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4619/261189169.py:43: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped = df.groupby(\"selected_user\").apply(compute_metrics).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected_user</th>\n",
       "      <th>correct_count</th>\n",
       "      <th>incorrect_count</th>\n",
       "      <th>average_rating_total</th>\n",
       "      <th>average_rating_correct</th>\n",
       "      <th>average_rating_incorrect</th>\n",
       "      <th>average_duration_total</th>\n",
       "      <th>average_distance_total</th>\n",
       "      <th>average_distance_correct</th>\n",
       "      <th>average_distance_incorrect</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI_Expert</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.612903</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.769231</td>\n",
       "      <td>11.479697</td>\n",
       "      <td>0.871528</td>\n",
       "      <td>0.858722</td>\n",
       "      <td>0.874374</td>\n",
       "      <td>18.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HdM_Student</td>\n",
       "      <td>28.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5.310345</td>\n",
       "      <td>7.964286</td>\n",
       "      <td>4.050847</td>\n",
       "      <td>13.591494</td>\n",
       "      <td>0.899664</td>\n",
       "      <td>0.864883</td>\n",
       "      <td>0.916170</td>\n",
       "      <td>32.183908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_User</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.448980</td>\n",
       "      <td>8.636364</td>\n",
       "      <td>4.526316</td>\n",
       "      <td>14.221400</td>\n",
       "      <td>0.894206</td>\n",
       "      <td>0.857618</td>\n",
       "      <td>0.904526</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All Users</td>\n",
       "      <td>45.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>4.850299</td>\n",
       "      <td>8.022727</td>\n",
       "      <td>3.715447</td>\n",
       "      <td>13.366824</td>\n",
       "      <td>0.892597</td>\n",
       "      <td>0.862286</td>\n",
       "      <td>0.903509</td>\n",
       "      <td>26.470588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  selected_user  correct_count  incorrect_count  average_rating_total  \\\n",
       "0     AI_Expert            6.0             27.0              2.612903   \n",
       "1   HdM_Student           28.0             59.0              5.310345   \n",
       "2   random_User           11.0             39.0              5.448980   \n",
       "3     All Users           45.0            125.0              4.850299   \n",
       "\n",
       "   average_rating_correct  average_rating_incorrect  average_duration_total  \\\n",
       "0                7.000000                  1.769231               11.479697   \n",
       "1                7.964286                  4.050847               13.591494   \n",
       "2                8.636364                  4.526316               14.221400   \n",
       "3                8.022727                  3.715447               13.366824   \n",
       "\n",
       "   average_distance_total  average_distance_correct  \\\n",
       "0                0.871528                  0.858722   \n",
       "1                0.899664                  0.864883   \n",
       "2                0.894206                  0.857618   \n",
       "3                0.892597                  0.862286   \n",
       "\n",
       "   average_distance_incorrect   accuracy  \n",
       "0                    0.874374  18.181818  \n",
       "1                    0.916170  32.183908  \n",
       "2                    0.904526  22.000000  \n",
       "3                    0.903509  26.470588  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_group_evaluation_clean = evaluate_user_groups_extended(df_clean)\n",
    "# Calculate accuracy for each user group as a new column in the evaluation DataFrame\n",
    "user_group_evaluation_clean['accuracy'] = (user_group_evaluation_clean['correct_count'] / (\n",
    "    user_group_evaluation_clean['correct_count'] + user_group_evaluation_clean['incorrect_count']\n",
    ")) *100\n",
    "display(user_group_evaluation_clean)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BAp11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
